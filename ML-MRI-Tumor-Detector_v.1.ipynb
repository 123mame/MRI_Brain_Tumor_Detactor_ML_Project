{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c56d2df4-950b-4827-a622-a847ce594873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#follow the command to install any package:\n",
    "#!pip install torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b910a05-dc88-4d3e-939b-e4394fb6c22e",
   "metadata": {},
   "source": [
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0dfaf053-8ba9-439f-80c0-1cc3d8fad7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the librarry\n",
    "\n",
    "import numpy as np  # For mathematical computations and array operations\n",
    "import torch  # For deep learning, tensor computations, and GPU acceleration\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset  # For handling and loading datasets efficiently\n",
    "import glob  # For file searching and pattern matching in directories to get the images\n",
    "import matplotlib.pyplot as plt  # For data visualization and plotting graphs and see the model expriance in vizualize\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score  # For evaluating model performance, mainly Conf_Matrix\n",
    "import random  # For generating random numbers and shuffling data\n",
    "import cv2  # For image processing and computer vision tasks\n",
    "import sys  # For system-specific parameters and functions, such as handling command-line arguments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3109b1-bdee-4663-a485-83211c5ab4ad",
   "metadata": {},
   "source": [
    "### Reading the images:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa053fe4-a406-4dd5-9dc0-ab348c79de91",
   "metadata": {},
   "source": [
    "##### Import the data from :https://www.kaggle.com/datasets/navoneel/brain-mri-images-for-brain-tumor-detection?resource=download\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f4c1315f-64ab-4a7d-82f4-991b11b079fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tumor count: 155\n",
      "Healthy count: 98\n"
     ]
    }
   ],
   "source": [
    "tumor = []\n",
    "\n",
    "#Matches .png, .jpeg, .jpg, .JPG, .JPEG, .PNG (case-insensitive).\n",
    "\n",
    "    #[pPjJ] → Matches p, P, j, or J (for png, jpg, jpeg).\n",
    "\n",
    "    #[nNpP]* → Matches optional n, N, or p, P (for png, jpeg).\n",
    "\n",
    "    #[gG] → Ensures it ends with g or G.\n",
    "\n",
    "path = './archive/brain_tumor_dataset/yes/*.[pPjJ][nNpP]*[gG]' \n",
    "\n",
    "for f in glob.iglob(path):\n",
    "    img = cv2.imread(f) # Reading the each image from the path\n",
    "    \n",
    "    #Since the data has different dimension, we have to have conssistant dimensions.\n",
    "    #Let's fix it \n",
    "    img = cv2.resize(img, (128,128)) # the dimension of the image set or resize  to 128x128pxl\n",
    "   \n",
    "    #Not essentiall but nice to have conventionally \n",
    "    b, g, r = cv2.split(img) # spliting the image in blue, green, and red Channals\n",
    "    img = cv2.merge([r, g, b]) # Then Merge by red, green, blue (RGB) order\n",
    "    \n",
    "    tumor.append(img) # Append the img to tumor list \n",
    "    \n",
    "print (\"Tumor count:\",len(tumor))\n",
    "\n",
    "\n",
    "healthy=[]\n",
    "\n",
    "for f in glob.iglob(\"./archive/brain_tumor_dataset/no/*.[pPjJ][nNpP]*[gG]\"):\n",
    "    img = cv2.imread(f)\n",
    "    img = cv2.resize(img,(128,128)) \n",
    "    b, g, r = cv2.split(img)\n",
    "    img = cv2.merge([r,g,b])\n",
    "    healthy.append(img)\n",
    "\n",
    "print (\"Healthy count:\", len(healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2225bef9-f183-4804-aa62-52a78e712f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This are the sape of the image: (128, 128, 3)\n",
      "This are the sape of the image: (128, 128, 3)\n",
      "This are the sape of the image: (128, 128, 3)\n",
      "This are the sape of the image: (128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "#Check the size of the image\n",
    "for i in tumor[1:5]:\n",
    "    print(\"This are the sape of the image:\", i.shape)\n",
    "#128 by 128 dimension by 3 channals (RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "3a66114c-6c35-46e6-b267-50341477e7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert to array\n",
    "healthy = np.array(healthy)\n",
    "tumor = np.array(tumor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d509ccb3-daa6-4858-aa6e-6e0f3dcb517d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 128, 128, 3)\n",
      "(98, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(tumor.shape)\n",
    "print(healthy.shape)\n",
    "# For example: For healthy we have 155 image, with 3 channals in dimension of 128 x128 pxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9c3a08b1-732f-4a38-be25-c993c6def483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "ALL = np.concatenate((healthy, tumor))\n",
    "print(ALL.shape) # the image joined and become 155 + 98 = 253."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59911e04-737b-44f5-8554-b480dfb0e2e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2d7d24-6700-4a9d-9fd2-82b6653b8882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dd1987-9851-4cc6-a44a-a075dcc9af9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16250f8-87ef-4bc9-b18a-3237f0346494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7f1c9f-d25d-4ee0-97cb-662a7949e8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b852312-8d03-433f-9333-e8a7434c10f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdd9db-44ce-46dc-9736-9063c7e680f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
